---
layout: default
---


# Documentation of earlier projects

## AI-related musical works

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/87S43pbpMY4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>
<br/>
<em>aletheia</em> (2022) est une pièce musicale basée sur l'exploration, la transformation, le piratage, le détournement et l'interaction avec des modèles génératifs audio. Se référant à la notion présocratique d'aletheia, cette pièce illustre la découverte de la réalité des modèles de synthèse audio neuronale en passant d'une pure perception phénoménologique à un jeu d'imitation, aboutissant à une version déréglée et coercitive de la réalité. En plus de tenter un travail réflexif entre les aspects philosophiques de la réalité et l'exploration des structures du modèle par altération, aletheia est motivée par le développement expérimental de nouvelles approches pour composer et interagir avec les modèles génératifs neuronaux, et par les nouvelles esthétiques qu'ils peuvent apporter. La pièce a été jouée au Cirque Électrique (Paris), à La Haye (Pays-Bas) et à Tokyo (Japon).

<br/>

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zGnvID6EMbU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>
<em>aego</em> (2018; 2022) est une performance qui met en scène une improvisation joine entre une personne, un agent exploratif, et un réseau de neurones génératif. La machine explore avec incertitude un espace latent spectral, tandis que la personne communique un renforcement positif ou négatif, en tournant ses mains vers l'avant ou vers l'arrière, pour tenter d'enseigner à la machine comment explorer cet espace. Progressivement, la personne renonce à communiquer un renforcement cohérent à la machine, laissant l'apprentissage de la machine indéterminé. Libérée de l'obligation d'enregistrer ses préférences dans la machine, la personne s'engage dans une écoute profonde du son et apprend à improviser à travers le son même.

<br/>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/f9-iXlb-ADw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>
<em>you will get what you leave behind</em> (2023) est une performance mixte basée sur l'exploration en temps réel de dispositifs de synthèse audio neuronale. Structurée comme un tryptique, cette performance expose la relation complexe entre ces technologies modernes et la matérialité de leur mémoire, dévoilant simultanément leur hanthologie sous-jacente (dans l'angoisse mais aussi dans l'onirisme) et leur matérialité (par leur nature conjointement réelle et irréelle, vivante et non vivante), offrant ainsi de nouveaux monstres, tantôt familiers, tantôt inquiétants, voire terrifiants. Le projet est actuellement en résidence au Château Éphèmère (France), et sera produit courant 2024.

<br/>
<center>
<iframe style="border: 0; width: 350px; height: 470px;" src="https://bandcamp.com/EmbeddedPlayer/album=3240089844/size=large/bgcol=ffffff/linkcol=0687f5/tracklist=false/transparent=true/" seamless><a href="https://daim.bandcamp.com/album/natures-d-couverte">Natures&amp;Découverte de Daim™</a></iframe>
<iframe style="border: 0; width: 350px; height: 470px;" src="https://bandcamp.com/EmbeddedPlayer/album=2012367212/size=large/bgcol=ffffff/linkcol=0687f5/tracklist=false/transparent=true/" seamless><a href="https://daim.bandcamp.com/album/natures-d-couverte-the-tenth-tenth-anniversary-edition">Natures&amp;D​é​couverte The Tenth Tenth Anniversary Edition de Daim™</a></iframe>
</center>
<em>Nature&Découvertes</em> du trio Daim™ explore les codes de la musique publicitaire en mettant en musique les 24 heures d'un travailleur de classe moyenne sans sommeil, couvert par une assurance créative mythique appelée w.lfg.ng. Une "1010th anniversary edition", sortie en 2023, est un side-album où chaque morceau est donné à une IA générative, entraînée sur la discographie de Daim™, ou chaque morceau est progressivement de plus en plus regurgité par la machine. Ce processus aboutit ensuite à une disparition progressive et à l'oubli, en raison de la sur-normalisation du processus effectué par l'IA.
<br/>
<br/>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8nYz_kTjetA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>
<em>deepscape</em> (2023) est une collaboration avec Hugo Scurto. deepscape est un travail conceptuel et technique visant à pratiquer et à théoriser à travers/sur le deepscape, qui peut désigner les flux mondiaux de médias intensivement calculés par l'apprentissage profond à travers Internet, enchevêtrés avec les ressources matérielles, humaines et culturelles qu'ils capitalisent à travers les infrastructures de l'intelligence artificielle industrielle. Ce projet vise à explorer l'écoute profonde des paysages sonores générés par l'apprentissage profond en tant que pratique de sensibilisation à l'échelle planétaire du paysage profond, en entraînant un modèle [RAVE](https://github.com/acids-ircam/RAVE) sur des données de paysages sonores mondiaux que j'ai enregistrées transversalement sur 28 lieux à la fin du mois d'avril 2022, en utilisant la carte sonore en ligne Locustream.
<br/>
<br/>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLScv8n5132x_6OR7cPQ2yWW4GDtOboRWW" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>
<em>ACIDS workshop</em> (2023-) est une série de spectacles que j'ai initiée à l'IRCAM avec des chercheurs, des compositeurs et des musiciens. L'objectif, avec ce concert à entrée libre, était d'offrir une carte blanche à toute personne intéressée par la création musicale avec la synthèse neuronale alimentée par l'IA, sans autre exigence esthétique que la rencontre en direct entre une équipe de recherche, des interprètes, des compositeurs et leur public. La première édition, qui a eu lieu en janvier 2022, a été suivie d'une édition avec des artistes de cirque du CNAC (Centre National des Arts du Cirques), puis d'une seconde édition en novembre 2022.



## AI-related artistical works

{% include image-gallery.html folder="/assets/images/works/inception-ghosts-i" %}
<em>Inception Ghosts</em> est une série d'images générées par l'IA, qui a pour but d'exposer les critères intrisèques aux algorithmes de classification d'images basés sur l'apprentissage automatique. Un générateur initialisé de manière aléatoire est entraîné à maximiser l'objectif que ces classificateurs doivent maximiser pour juger de leur quality; de cette manière, le générateur peut en quelque sorte "absorber" leur fonctionnement interne, fournissant des images abstraites qui, paradoxalement, sont classées de manière optimale.

{% include image-gallery.html folder="/assets/images/works/cloud" %}
[The Cloud](https://arkadizaides.com/the-cloud) est une performance d'Arkadi Zaides qui met en lumière la catastrophe de Tchernobyl en suivant le mouvement du nuage radioactif, ses retombées et le danger qu'il représente toujours pour les humains. Ce projet utilise plusieurs algorithmes de génération de textes, d'images et de sons basés sur l'IA pour explorer sur scène les limites mêmes de la réalité et de la croyance. Ce projet est produit par l'Institut des Croisements et coproduit par Montpellier Danse (FR), laGeste (BE), Charleroi Danse (BE), Maison de la Danse (FR), avec le soutien de la résidence PACT Zollverein (DE), Teatro Biblioteca Quarticciolo (IT), CAMPO (BE), et avec le soutien du Ministère de la Culture de France / Direction Générale de la Création Artistique, TMU New York.


## AI-related works

### Code
[vschaos](https://github.com/acids-ircam/vschaos2) est un auto-encodeur spectral qui peut être utilisé pour génerer des spectro-morphologies à évolution longue, qui peut être utilisé en temps réel grâce aux logiciels Max et PureData. Ce travail, qui était l'un des produits de mon doctorat et l'un des premiers modèles génératifs d'IA en temps réel utilisables, a été utilisé dans la performance d'aego en 2019. Je l'ai récemment recodé pour qu'il soit disponible avec les architectures modernes, offrant ainsi une synthèse audio neuronale exploratoire et légère.

[nn~](https://github.com/acids-ircam/nn_tilde) initié par Antoine Caillon est une interface utilisée dans le monde entier pour intégrer la synthèse audio neuronale en temps réel dans des logiciels de synthèse sonore comme PureData et Max pour des performances d'IA en temps réel. J'ai contribué au développement après la première version, ajoutant quelques fonctionnalités et en continuant à travailler sur les possibilités créatives de détournement créatif, ainsi que sur la multi-modalité.

[RAVE-VST](https://github.com/acids-ircam/rave_vst) est un VST intégrant RAVE en tant que synthétiseur pouvant être intégré dans une DAW, dont j'ai développé le traitement du signal et contribué à la conception de l'interface utilisateur.

[divergent-synthesis](https://github.com/domkirke/divergent-synthesis) sont les premières expériences d'une méthode d'apprentissage extrapolatif pour les IA génératives appelée Bounded Adversarial Divergence (BAD), basé sur l'adaptation de modèles génératifs pré-entraînés à l'aide de classificateurs neuronaux. 

### Slideshows
[Presentation in Sorbonne Universités](/assets/documents/sorbonne.pdf) pour le séminaire Textures Électroniques, organisé par l'artiste Kaspar Ravel (2023)


### Article selection
- Scurto H. & Chemla—Romeu-Santos Axel, [Deeply Listening Through/Out the Deepscape](https://hal.science/hal-04108995/file/scurto2023deeply.pdf), ISEA2023
- Chemla–Romeu-Santos A. & Esling P., [Creative divergent synthesis with generative models](https://domkirke.github.io/ai;code;experiments;articles/2022/09/12/badneurips.html) (arXiv)
- Chemla–Romeu-Santos A., [aletheia](/assets/documents/aletheia.pdf), AIMC2022 (musical paper)
- Chemla–Romeu-Santos A. & Esling P., [Challenges in creative generative models: a divergence maximization perspective](https://arxiv.org/pdf/2211.08856.pdf), AIMC2022 (research paper)
- Chemla–Romeu-Santos A., [Représentations variationnelles inversibles: Une nouvelle approche pour la synthèse sonore](https://hal.archives-ouvertes.fr/hal-03353913/), JIM, 2020
- Chemla–Romeu-Santos A., Scurto H. [Machine Learning for Computer Music Multidisciplinary Research: A Practical Case Study](https://hal.archives-ouvertes.fr/hal-02408699/). CMMR, 2019. 
- Chemla–Romeu-Santos A., Ntalampiras S., Esling P., Haus G., Assayag G. [Cross-Modal Variational Inference for Bijective Signal-Symbol Translation](https://hal.archives-ouvertes.fr/hal-02471810/). DAFX Proceedings 2019 (2019). 
- Esling, P., Chemla—Romeu-Santos, A., Bitton, A. [Bridging audio analysis, perception and synthesis with perceptually-regularized variational timbre spaces](http://ismir2018.ircam.fr/doc/pdfs/219_Paper.pdf) , ISMIR2018 (2018) 
- Nika, J., Déguernel, K., Chemla—Romeu-Santos, A. [DYCI2 agents: merging the" free"," reactive", and" scenario-based" music generation paradigms](https://hal.science/hal-01583089/file/DYCI2_CreativeAgents_Nika_al.pdf). International Computer Music Conference (2017)